# Sistema de Logging e Issues Autom√°ticas para Scraping

Documenta√ß√£o do sistema de logging aprimorado e gera√ß√£o autom√°tica de issues no GitHub para falhas de scraping.

## Vis√£o Geral

O sistema de scraping foi melhorado para:
1. **Logs vis√≠veis no console do Render** com formata√ß√£o clara
2. **Cria√ß√£o autom√°tica de issues no GitHub** quando falhas de parsing ocorrem
3. **Diferencia√ß√£o entre erros de rede e erros de parsing**

## Tipos de Erro

### 1. NetworkError (Erro de Rede/HTTP)
**O que √©**: Problemas ao acessar a URL (404, 500, timeout, conex√£o falhou, etc.)

**Comportamento**:
- ‚ùå **N√ÉO gera issue no GitHub** (s√£o erros tempor√°rios/externos)
- ‚ö†Ô∏è  Log de warning no console
- Retorna `error_type: 'network'`

**Exemplos**:
- HTTP 404 (p√°gina n√£o encontrada)
- HTTP 500 (erro do servidor)
- Timeout (servidor n√£o respondeu)
- Connection refused (servidor offline)

**Log no Console**:
```
================================================================================
‚ö†Ô∏è  ERRO DE REDE ao acessar: https://amazon.com.br/produto/12345
   Status HTTP: 404
   Erro: Erro HTTP 404: Not Found
================================================================================
```

### 2. ParsingError (Erro de Extra√ß√£o de Dados)
**O que √©**: Site acess√≠vel mas dados n√£o podem ser extra√≠dos (t√≠tulo, pre√ßo, imagem)

**Comportamento**:
- ‚úÖ **GERA issue no GitHub automaticamente**
- ‚ùå Log de erro no console
- Retorna `error_type: 'parsing'`
- Issue criada com labels: `auto-generated`, `enhancement`, `scraping`

**Exemplos**:
- Site mudou estrutura HTML
- Site n√£o suportado pelo sistema
- Scraper desatualizado
- Site protegido (captcha, anti-bot)

**Log no Console**:
```
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
‚ùå ERRO CR√çTICO DE SCRAPING - AMAZON
   URL: https://amazon.com.br/produto/12345
   T√≠tulo: N√£o extra√≠do ‚ùå
   Pre√ßo: N√£o extra√≠do
   Imagem: N√£o extra√≠da

   ‚ö†Ô∏è  ATEN√á√ÉO: Issue ser√° criada automaticamente no GitHub
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

================================================================================
‚ö†Ô∏è  ERRO DE PARSING ao extrair dados de: https://amazon.com.br/produto/12345
   Erro: Nao foi possivel extrair titulo da Amazon. Dados parciais: preco=None, imagem=False

   ‚ÑπÔ∏è  Tentando criar issue no GitHub automaticamente...
================================================================================
‚úÖ Issue #123 criada: https://github.com/Maxwbh/Lista_de_Presentes/issues/123
```

## Logs de Sucesso

### Amazon
```
================================================================================
üõçÔ∏è  AMAZON SCRAPING - URL: https://amazon.com.br/produto/12345...
   üìù T√≠tulo:  ‚úÖ Extra√≠do - Produto XYZ Incr√≠vel e Maravilhoso...
   üí∞ Pre√ßo:   ‚úÖ Extra√≠do - R$ 199.90
   üñºÔ∏è  Imagem:  ‚úÖ Extra√≠da
================================================================================
```

### Mercado Livre
```
================================================================================
üõí MERCADO LIVRE SCRAPING - URL: https://mercadolivre.com.br/MLB-12345...
   üìù T√≠tulo:  ‚úÖ Extra√≠do - Produto ABC...
   üí∞ Pre√ßo:   ‚úÖ Extra√≠do - R$ 299.90
   üñºÔ∏è  Imagem:  ‚ö†Ô∏è  N√£o encontrada
================================================================================
```

### Kabum
```
================================================================================
üéÆ KABUM SCRAPING - URL: https://kabum.com.br/produto/12345...
   üìù T√≠tulo:  ‚úÖ Extra√≠do - Placa de V√≠deo...
   üí∞ Pre√ßo:   ‚ö†Ô∏è  N√£o encontrado
   üñºÔ∏è  Imagem:  ‚úÖ Extra√≠da
================================================================================
```

### Generic (Site Desconhecido)
```
================================================================================
üåê SCRAPING GEN√âRICO - URL: https://loja-desconhecida.com.br/produto...
   üìù T√≠tulo:  ‚úÖ Extra√≠do - Produto Teste...
   üí∞ Pre√ßo:   ‚úÖ Extra√≠do - R$ 99.99
   üñºÔ∏è  Imagem:  ‚úÖ Extra√≠da
================================================================================
```

## Issues Autom√°ticas no GitHub

### Requisitos

As seguintes vari√°veis de ambiente devem estar configuradas:

```bash
# Render Dashboard > Environment Variables
GITHUB_TOKEN=ghp_...                           # Token de acesso pessoal
GITHUB_REPO_OWNER=Maxwbh                       # Dono do reposit√≥rio
GITHUB_REPO_NAME=Lista_de_Presentes            # Nome do reposit√≥rio
GITHUB_AUTO_CREATE_ISSUES=True                 # Habilitar auto-cria√ß√£o
```

### Estrutura da Issue Criada

**T√≠tulo**:
```
[AUTO] Falha ao extrair dados: amazon.com.br
```

**Labels**:
- `auto-generated` - Issue criada automaticamente
- `enhancement` - Melhoria necess√°ria
- `scraping` - Relacionado a scraping
- `needs-triage` - Precisa an√°lise
- `extracao-titulo` - Se t√≠tulo falhou
- `extracao-preco` - Se pre√ßo falhou
- `extracao-imagem` - Se imagem falhou

**Corpo da Issue**:
```markdown
## Falha Automatica na Extracao de Dados de Produto

### Problema Detectado
O sistema conseguiu acessar a URL do produto (sem erros HTTP), mas **nao conseguiu extrair** os seguintes dados:
**T√≠tulo, Pre√ßo**

Este tipo de erro indica que:
1. O site mudou sua estrutura HTML
2. O site nao e suportado pelo sistema
3. O template de extracao precisa ser atualizado

### URL do Produto
```
https://amazon.com.br/produto/12345
```

### Dominio
`amazon.com.br`

### Dados Extraidos (Parcialmente)
- **Titulo**: ‚ùå Nao extraido
- **Preco**: ‚ùå Nao extraido
- **Imagem**: ‚úÖ https://m.media-amazon.com/images/...

### Contexto do Usuario
- **Usuario**: N/A
- **Grupo**: N/A
- **Data**: 2026-02-03 17:30:00

### Acoes Sugeridas
- [ ] Verificar se o dominio `amazon.com.br` ja esta implementado em `scrapers.py`
- [ ] Acessar a URL manualmente e inspecionar a estrutura HTML
- [ ] Verificar se o site usa JavaScript para carregar dados (SPA)
- [ ] Implementar scraper especifico para `amazon.com.br` se for site conhecido
- [ ] Atualizar scraper generico para detectar novos padroes
- [ ] Verificar se o site tem protecao anti-bot (Cloudflare, etc.)

### Informacoes Tecnicas
- **Tipo de erro**: Falha de scraping/parsing (site acessivel)
- **Origem**: Sistema automatico de extracao via URL
- **Severidade**: Media
- **Categoria**: Enhancement/Bug
- **Necessita acao**: Sim - atualizar scrapers

### Como Reproduzir
1. Acessar sistema
2. Adicionar novo presente
3. Inserir URL: `https://amazon.com.br/produto/12345`
4. Tentar extrair dados automaticamente
5. Observar que campos nao sao preenchidos

---
*Esta issue foi criada automaticamente quando o sistema detectou falha na extracao de dados.*
*Versao: 1.1.13*
```

## Configura√ß√£o do GitHub Token

### 1. Criar Token no GitHub

1. Acesse: https://github.com/settings/tokens
2. Clique em "Generate new token" > "Classic"
3. Nome: `Lista de Presentes - Auto Issues`
4. Expiration: `No expiration` (ou 90 dias)
5. Scopes necess√°rios:
   - ‚úÖ `repo` (acesso completo a reposit√≥rios privados/p√∫blicos)
     - ‚úÖ `repo:status`
     - ‚úÖ `repo_deployment`
     - ‚úÖ `public_repo`
     - ‚úÖ `repo:invite`
     - ‚úÖ `security_events`
6. Clique em "Generate token"
7. **COPIE O TOKEN** (voc√™ n√£o ver√° novamente!)

### 2. Adicionar no Render

1. Dashboard do Render > Service > Environment
2. Adicionar vari√°vel: `GITHUB_TOKEN`
3. Valor: Cole o token copiado
4. Save Changes
5. Redeploy (manual ou aguardar pr√≥ximo deploy)

### 3. Testar

```python
# Via Render Shell ou localmente
python manage.py shell

from presentes.github_helper import criar_issue_falha_scraping

result = criar_issue_falha_scraping(
    url_produto='https://amazon.com.br/teste',
    dados_extraidos={'titulo': None, 'preco': None, 'imagem_url': None},
)

print(result)
# Deve retornar: {'success': True, 'issue_number': 123, 'issue_url': '...'}
```

## Desabilitar Issues Autom√°ticas

Para desabilitar temporariamente (sem remover token):

```bash
# Render Dashboard > Environment
GITHUB_AUTO_CREATE_ISSUES=False
```

## Monitoramento no Render

### Ver Logs em Tempo Real

1. Render Dashboard > Service > Logs
2. Procurar por:
   - `üõçÔ∏è` - Scraping Amazon
   - `üõí` - Scraping Mercado Livre
   - `üéÆ` - Scraping Kabum
   - `üåê` - Scraping Gen√©rico
   - `‚úÖ` - Sucesso
   - `‚ùå` - Erro cr√≠tico
   - `‚ö†Ô∏è` - Warning

### Filtrar Logs

```bash
# Apenas sucessos
grep "‚úÖ" logs.txt

# Apenas erros cr√≠ticos
grep "‚ùå ERRO CR√çTICO" logs.txt

# Apenas parsing errors
grep "ERRO DE PARSING" logs.txt

# Issues criadas
grep "Issue #" logs.txt
```

## An√°lise de Problemas

### Issue Criada Mas N√£o Devia

**Causa**: `GITHUB_AUTO_CREATE_ISSUES=True` est√° ativo

**Solu√ß√£o**:
1. Desabilitar: `GITHUB_AUTO_CREATE_ISSUES=False`
2. Ou remover `GITHUB_TOKEN`

### Issue N√£o Criada Mas Devia

**Causa Poss√≠vel 1**: Token inv√°lido/expirado
```bash
# Verificar logs
grep "GITHUB_TOKEN nao configurado" logs.txt
grep "Falha ao criar issue" logs.txt
```

**Solu√ß√£o**: Gerar novo token e atualizar `GITHUB_TOKEN`

**Causa Poss√≠vel 2**: Feature desabilitada
```bash
# Verificar
echo $GITHUB_AUTO_CREATE_ISSUES  # Deve ser "True"
```

**Solu√ß√£o**: `GITHUB_AUTO_CREATE_ISSUES=True`

**Causa Poss√≠vel 3**: NetworkError (n√£o deve gerar issue)
```bash
# Verificar se foi erro de rede (404, 500, timeout)
grep "ERRO DE REDE" logs.txt
```

**Solu√ß√£o**: NetworkErrors s√£o esperados e n√£o geram issues

### Logs N√£o Aparecem

**Causa**: N√≠vel de log configurado incorretamente

**Solu√ß√£o**: Verificar `settings.py`:
```python
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',  # Deve ser INFO ou DEBUG
        },
    },
    'loggers': {
        'presentes': {
            'handlers': ['console'],
            'level': 'INFO',  # Deve ser INFO ou DEBUG
        },
    },
}
```

## Estat√≠sticas

Para an√°lise de problemas, use os logs:

```bash
# Quantas falhas de scraping hoje?
grep "ERRO CR√çTICO DE SCRAPING" logs.txt | wc -l

# Quais sites falharam mais?
grep "ERRO CR√çTICO DE SCRAPING" logs.txt | grep -oP "(?<=SCRAPING - )[A-Z]+" | sort | uniq -c

# Quantas issues foram criadas?
grep "Issue #[0-9]+ criada" logs.txt | wc -l

# Taxa de sucesso por site
grep -c "AMAZON.*‚úÖ Extra√≠do" logs.txt
```

## Changelog

### v1.1.14 (2026-02-03)
- ‚ú® Logs formatados com emojis e separadores visuais
- ‚ú® Diferencia√ß√£o clara entre NetworkError e ParsingError
- ‚ú® Integra√ß√£o autom√°tica com cria√ß√£o de issues no GitHub
- ‚ú® Logs de erro cr√≠tico bem vis√≠veis no console do Render
- ‚ú® Informa√ß√£o de cria√ß√£o de issue nos logs
- üìù Documenta√ß√£o completa do sistema de logging

## Contato

D√∫vidas ou problemas:
- Maxwell Oliveira (@maxwbh)
- maxwbh@gmail.com

## Refer√™ncias

- [Scrapers Implementation](presentes/scrapers.py)
- [GitHub Helper](presentes/github_helper.py)
- [Django Logging](https://docs.djangoproject.com/en/4.2/topics/logging/)
